2023-08-26 17:42:59,543 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 17:42:59,555 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 17:43:02,942 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 17:43:04,878 - kedro.pipeline.node - INFO - Running node: zebi: join_statements([train_comments]) -> [train_processed]
2023-08-26 17:43:04,918 - kedro.io.data_catalog - INFO - Saving data to 'train_processed' (MemoryDataset)...
2023-08-26 17:43:04,996 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 17:43:05,002 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 17:43:05,006 - kedro.io.data_catalog - INFO - Loading data from 'train_processed' (MemoryDataset)...
2023-08-26 17:43:46,999 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 17:43:47,015 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 17:43:48,457 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 17:43:50,441 - kedro.pipeline.node - INFO - Running node: zebi: join_statements([train_comments]) -> [train_processed]
2023-08-26 17:43:50,495 - kedro.io.data_catalog - INFO - Saving data to 'train_processed' (MemoryDataset)...
2023-08-26 17:43:50,541 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 17:43:50,546 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 17:43:50,551 - kedro.io.data_catalog - INFO - Loading data from 'train_processed' (MemoryDataset)...
2023-08-26 17:44:36,830 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 17:44:36,840 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 17:44:38,253 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 17:44:40,267 - kedro.pipeline.node - INFO - Running node: zebi: join_statements([train_comments]) -> [train_comments_processed]
2023-08-26 17:44:40,321 - kedro.io.data_catalog - INFO - Saving data to 'train_comments_processed' (CSVDataSet)...
2023-08-26 17:44:44,629 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 17:44:44,644 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 18:12:59,162 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:12:59,177 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:13:00,608 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:13:02,513 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:13:02,623 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 18:13:02,628 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 18:28:37,125 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:28:37,136 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:28:38,561 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:28:40,533 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:28:40,568 - kedro.pipeline.node - ERROR - Node 'zebi: preprocess([train_comments]) -> None' failed with error: 
No axis named 1 for object type Series
2023-08-26 18:28:40,587 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-08-26 18:29:32,929 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:29:32,945 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:29:34,542 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:29:36,588 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:29:36,619 - kedro.pipeline.node - ERROR - Node 'zebi: preprocess([train_comments]) -> None' failed with error: 
No axis named 1 for object type Series
2023-08-26 18:29:36,647 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-08-26 18:36:16,293 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:36:16,303 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:36:16,331 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\project\__init__.py:359: UserWarning: An error occurred while importing the 'granlp.pipelines.preprocessing' module. Nothing defined therein will be returned by 'find_pipelines'.

Traceback (most recent call last):
  File "C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\project\__init__.py", line 357, in find_pipelines
    pipeline_module = importlib.import_module(pipeline_module_name)
  File "D:\Softwares\Python\Python310\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\preprocessing\__init__.py", line 6, in <module>
    from .pipeline import create_pipeline
  File "C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\preprocessing\pipeline.py", line 7, in <module>
    from .nodes import join_statements,preprocess
  File "C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\preprocessing\nodes.py", line 36
    print(f"The shape of our dataset {train_data["comment_text"] .shape}")
                                                  ^^^^^^^^^^^^
SyntaxError: f-string: unmatched '['

  warnings.warn(

2023-08-26 18:37:18,369 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:37:18,384 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:37:19,976 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:37:22,072 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:37:27,548 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 18:37:27,552 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 18:37:42,906 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:37:42,916 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:37:44,332 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:37:46,208 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:37:51,203 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 18:37:51,207 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 18:38:59,740 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:38:59,740 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:39:01,159 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:39:03,019 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:39:17,934 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 18:39:17,939 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-26 18:39:34,674 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-26 18:39:34,685 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-26 18:39:36,239 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-26 18:39:38,472 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> None
2023-08-26 18:39:53,719 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-26 18:39:53,724 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-27 19:41:28,997 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-27 19:41:29,012 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-27 19:41:31,027 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-27 19:41:33,074 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> [train_comments_processed]
2023-08-27 19:41:48,013 - kedro.io.data_catalog - INFO - Saving data to 'train_comments_processed' (CSVDataSet)...
2023-08-27 19:41:48,018 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-08-27 19:42:13,265 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-27 19:42:13,281 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-27 19:42:14,827 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-27 19:42:16,753 - kedro.pipeline.node - INFO - Running node: zebi: preprocess([train_comments]) -> [train_comments_processed]
2023-08-27 19:42:30,717 - kedro.io.data_catalog - INFO - Saving data to 'train_comments_processed' (CSVDataSet)...
2023-08-27 19:42:35,120 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-27 19:42:35,125 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-28 18:03:29,320 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-28 18:03:29,335 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-28 18:03:30,900 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-08-28 18:03:32,860 - kedro.pipeline.node - INFO - Running node: zebi: preprocess_train([train_comments]) -> [train_comments_processed]
2023-08-28 18:03:46,979 - kedro.io.data_catalog - INFO - Saving data to 'train_comments_processed' (CSVDataSet)...
2023-08-28 18:03:51,166 - kedro.runner.sequential_runner - INFO - Completed 1 out of 2 tasks
2023-08-28 18:03:51,172 - kedro.io.data_catalog - INFO - Loading data from 'test_comments' (CSVDataSet)...
2023-08-28 18:03:52,724 - kedro.pipeline.node - INFO - Running node: zebi2: preprocess_test([test_comments]) -> [test_comments_processed]
2023-08-28 18:04:01,043 - kedro.io.data_catalog - INFO - Saving data to 'test_comments_processed' (CSVDataSet)...
2023-08-28 18:04:04,519 - kedro.runner.sequential_runner - INFO - Completed 2 out of 2 tasks
2023-08-28 18:04:04,519 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-29 17:33:16,880 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-29 17:33:16,896 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-29 17:33:20,625 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\project\__init__.py:359: UserWarning: An error occurred while importing the 'granlp.pipelines.build_graph' module. Nothing defined therein will be returned by 'find_pipelines'.

Traceback (most recent call last):
  File "C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\project\__init__.py", line 357, in find_pipelines
    pipeline_module = importlib.import_module(pipeline_module_name)
  File "D:\Softwares\Python\Python310\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\build_graph\__init__.py", line 6, in <module>
    from .pipeline import create_pipeline
  File "C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\build_graph\pipeline.py", line 7, in <module>
    from .nodes import build_graph
  File "C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\build_graph\nodes.py", line 7, in <module>
    from utils import loadWord2Vec, clean_str
ModuleNotFoundError: No module named 'utils'

  warnings.warn(

2023-08-29 17:35:58,576 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-29 17:35:58,587 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-29 17:36:36,625 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-29 17:36:36,635 - py.warnings - WARNING - C:\Users\mrguig071323\AppData\Roaming\Python\Python310\site-packages\kedro\framework\session\session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-29 17:36:46,630 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-29 17:36:48,685 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-08-29 17:36:50,384 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x,y,tx,ty,allx,ally,adj]
2023-08-29 17:39:12,125 - py.warnings - WARNING - C:\Users\mrguig071323\Downloads\nlp6FILES-main (2)\nlp6FILES-main\granlp\src\granlp\pipelines\build_graph\nodes.py:216: RuntimeWarning: invalid value encountered in double_scalars
  data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len

2023-08-29 20:00:58,486 - kedro.io.data_catalog - INFO - Saving data to 'x' (MemoryDataset)...
2023-08-29 20:01:00,516 - kedro.io.data_catalog - INFO - Saving data to 'y' (MemoryDataset)...
2023-08-29 20:01:02,432 - kedro.io.data_catalog - INFO - Saving data to 'tx' (MemoryDataset)...
2023-08-29 20:01:04,640 - kedro.io.data_catalog - INFO - Saving data to 'ty' (MemoryDataset)...
2023-08-29 20:01:15,981 - kedro.io.data_catalog - INFO - Saving data to 'allx' (MemoryDataset)...
2023-08-29 20:01:33,159 - kedro.io.data_catalog - INFO - Saving data to 'ally' (MemoryDataset)...
2023-08-29 20:01:37,940 - kedro.io.data_catalog - INFO - Saving data to 'adj' (MemoryDataset)...
2023-08-29 20:01:46,958 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-29 20:01:46,973 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-29 20:01:46,973 - kedro.io.data_catalog - INFO - Loading data from 'x' (MemoryDataset)...
2023-08-29 20:01:47,751 - kedro.io.data_catalog - INFO - Loading data from 'ty' (MemoryDataset)...
2023-08-29 20:01:47,770 - kedro.io.data_catalog - INFO - Loading data from 'allx' (MemoryDataset)...
2023-08-29 20:01:53,058 - kedro.io.data_catalog - INFO - Loading data from 'y' (MemoryDataset)...
2023-08-29 20:01:53,073 - kedro.io.data_catalog - INFO - Loading data from 'ally' (MemoryDataset)...
2023-08-29 20:01:53,118 - kedro.io.data_catalog - INFO - Loading data from 'adj' (MemoryDataset)...
2023-08-29 20:01:55,172 - kedro.io.data_catalog - INFO - Loading data from 'tx' (MemoryDataset)...
2023-08-30 18:18:38,988 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 18:18:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 18:18:57,611 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 18:18:57,614 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 18:18:59,072 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-30 18:18:59,074 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-08-30 18:22:23,534 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 18:22:23,538 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 18:22:24,548 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-30 18:22:25,325 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-08-30 18:22:25,945 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x,y,tx,ty,allx,ally,adj]
2023-08-30 18:23:16,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py:216: RuntimeWarning: invalid value encountered in scalar divide
  data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len

2023-08-30 21:09:00,461 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 21:09:00,464 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 21:09:01,478 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-30 21:09:02,245 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-08-30 21:09:02,861 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x,y,tx,ty,allx,ally,adj]
2023-08-30 21:09:52,829 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py:216: RuntimeWarning: invalid value encountered in scalar divide
  data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len

2023-08-30 21:19:37,071 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 21:19:37,075 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 21:20:22,690 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 21:20:22,694 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 21:21:10,361 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 21:21:10,364 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 21:21:11,375 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-30 21:21:12,163 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-08-30 21:21:12,791 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x,y,tx,ty,allx,ally,adj]
2023-08-30 21:22:02,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py:216: RuntimeWarning: invalid value encountered in scalar divide
  data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len

2023-08-30 21:26:45,056 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-30 21:26:45,060 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-30 21:26:46,064 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-30 21:26:46,811 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-08-30 21:26:47,414 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x,y,tx,ty,allx,ally,adj]
2023-08-30 21:27:37,112 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py:216: RuntimeWarning: invalid value encountered in scalar divide
  data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len

2023-08-30 22:32:48,518 - kedro.io.data_catalog - INFO - Saving data to 'x' (MemoryDataset)...
2023-08-30 22:32:49,940 - kedro.io.data_catalog - INFO - Saving data to 'y' (MemoryDataset)...
2023-08-30 22:32:51,518 - kedro.io.data_catalog - INFO - Saving data to 'tx' (MemoryDataset)...
2023-08-30 22:32:52,878 - kedro.io.data_catalog - INFO - Saving data to 'ty' (MemoryDataset)...
2023-08-30 22:33:04,143 - kedro.io.data_catalog - INFO - Saving data to 'allx' (MemoryDataset)...
2023-08-30 22:33:14,578 - kedro.io.data_catalog - INFO - Saving data to 'ally' (MemoryDataset)...
2023-08-30 22:33:18,541 - kedro.io.data_catalog - INFO - Saving data to 'adj' (MemoryDataset)...
2023-08-30 22:33:22,699 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-08-30 22:33:22,701 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-08-30 22:33:22,702 - kedro.io.data_catalog - INFO - Loading data from 'ally' (MemoryDataset)...
2023-08-30 22:33:22,748 - kedro.io.data_catalog - INFO - Loading data from 'adj' (MemoryDataset)...
2023-08-30 22:33:23,948 - kedro.io.data_catalog - INFO - Loading data from 'ty' (MemoryDataset)...
2023-08-30 22:33:23,954 - kedro.io.data_catalog - INFO - Loading data from 'x' (MemoryDataset)...
2023-08-30 22:33:24,575 - kedro.io.data_catalog - INFO - Loading data from 'tx' (MemoryDataset)...
2023-08-30 22:33:25,230 - kedro.io.data_catalog - INFO - Loading data from 'y' (MemoryDataset)...
2023-08-30 22:33:25,235 - kedro.io.data_catalog - INFO - Loading data from 'allx' (MemoryDataset)...
2023-08-31 19:43:17,098 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-31 19:43:17,101 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-31 19:48:15,645 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-31 19:48:15,648 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-31 19:48:46,559 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-31 19:48:46,562 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-31 19:49:06,172 - kedro.framework.session.session - INFO - Kedro project granlp
2023-08-31 19:49:06,175 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-08-31 19:49:08,526 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-08-31 19:49:09,249 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-08-31 19:49:09,855 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]
2023-08-31 19:49:09,868 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]' failed with error: 
Can't load tokenizer for 'distilbert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'distilbert-base-uncased' is the correct path to a directory containing all relevant files for a DistilBertTokenizer tokenizer.
2023-08-31 19:49:09,878 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 14:28:35,642 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 14:28:35,645 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 14:28:38,067 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 14:28:38,805 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 14:28:39,421 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]
2023-09-01 14:28:39,422 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]' failed with error: 
Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'src/data/01_raw/distilbert-base-uncased'. Use `repo_type` argument if needed.
2023-09-01 14:28:39,430 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 14:29:13,597 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 14:29:13,600 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 14:29:16,127 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 14:29:16,871 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 14:29:17,489 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]
2023-09-01 14:29:17,491 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]' failed with error: 
Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'data/01_raw/distilbert-base-uncased'. Use `repo_type` argument if needed.
2023-09-01 14:29:17,499 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 14:29:56,966 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 14:29:56,969 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 14:29:59,347 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 14:30:00,088 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 14:30:00,702 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]
2023-09-01 14:30:00,746 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]' failed with error: 
Failed to save outputs of node zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x].
The node definition contains a list of outputs ['x'], whereas the node function returned a 'int'.
2023-09-01 14:30:00,754 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 14:31:08,224 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 14:31:08,227 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 14:31:10,607 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 14:31:11,341 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 14:31:11,955 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]
2023-09-01 14:31:11,998 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]' failed with error: 
Failed to save outputs of node zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x].
The node definition contains a list of outputs ['x'], whereas the node function returned a 'MultiLabelDataset'.
2023-09-01 14:31:12,006 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 14:31:32,940 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 14:31:32,944 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 14:31:35,304 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 14:31:36,040 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 14:31:36,651 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed]) -> [x]
2023-09-01 14:31:36,698 - kedro.io.data_catalog - INFO - Saving data to 'x' (MemoryDataset)...
2023-09-01 14:31:36,766 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 14:31:36,767 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 14:31:36,768 - kedro.io.data_catalog - INFO - Loading data from 'x' (MemoryDataset)...
2023-09-01 14:37:15,787 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 14:37:15,791 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 14:37:18,143 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 14:37:18,875 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 14:37:19,481 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 14:37:19,489 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x]
2023-09-01 14:37:19,531 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 14:37:19,538 - kedro.io.data_catalog - INFO - Saving data to 'x' (MemoryDataset)...
2023-09-01 14:37:19,605 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 14:37:19,607 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 14:37:19,608 - kedro.io.data_catalog - INFO - Loading data from 'x' (MemoryDataset)...
2023-09-01 15:59:20,950 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 15:59:20,954 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 15:59:41,482 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 15:59:41,486 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:00:08,518 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:00:08,521 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:00:27,303 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:00:27,307 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:00:41,639 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:00:41,643 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:01:26,732 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:01:26,735 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:01:29,178 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:01:29,915 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:01:30,525 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:01:30,533 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:01:30,559 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]' failed with error: 
'builtin_function_or_method' object has no attribute 'info'
2023-09-01 16:01:30,566 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:01:55,636 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:01:55,640 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:01:58,147 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:01:58,886 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:01:59,502 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:01:59,510 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:01:59,538 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:01:59,539 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:01:59,547 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 16:01:59,687 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 16:01:59,836 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 16:01:59,837 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 16:02:04,373 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:02:04,376 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:02:21,139 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:02:21,143 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:02:23,588 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:02:23,731 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:02:23,733 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:02:25,934 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
'<=' not supported between instances of 'float' and 'str'
2023-09-01 16:02:25,936 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:03:11,563 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:03:11,566 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:03:13,970 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:03:14,115 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:03:14,117 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:03:16,268 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
name 'tqdm' is not defined
2023-09-01 16:03:16,270 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:03:30,077 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:03:30,081 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:03:32,654 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:03:32,796 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:03:32,798 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:03:34,969 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
'module' object is not callable
2023-09-01 16:03:34,971 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:28:38,107 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:28:38,111 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:28:40,738 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:28:40,889 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:28:40,891 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:28:43,095 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
'module' object is not callable
2023-09-01 16:28:43,097 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:29:28,152 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:29:28,155 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:29:30,723 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:29:30,865 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:29:30,867 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:29:33,029 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:29:33,034 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
name 'torch' is not defined
2023-09-01 16:29:33,036 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:34:28,941 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:34:28,945 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:34:31,351 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:34:31,490 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:34:31,491 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:34:33,611 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:34:33,616 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
new(): invalid data type 'str'
2023-09-01 16:34:33,617 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:35:31,144 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:35:31,147 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:35:33,571 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:35:34,308 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:35:34,928 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:35:34,936 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:35:34,963 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:35:34,964 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:35:34,971 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 16:35:35,128 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 16:35:35,299 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 16:35:35,300 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 16:35:38,710 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:35:38,713 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:35:41,121 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:35:41,260 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:35:41,263 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:35:43,383 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:35:43,388 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
new(): invalid data type 'str'
2023-09-01 16:35:43,389 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:36:28,276 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:36:28,280 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:36:30,685 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:36:30,822 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:36:30,823 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:36:32,943 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:36:32,949 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
new(): invalid data type 'str'
2023-09-01 16:36:32,951 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:38:40,088 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:38:40,092 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:38:42,500 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:38:43,228 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:38:43,840 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:38:43,848 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:38:43,875 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:38:43,876 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:38:43,878 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:38:43,882 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]' failed with error: 
new(): invalid data type 'str'
2023-09-01 16:38:43,890 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:38:50,234 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:38:50,237 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:38:52,653 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:38:53,389 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:38:53,994 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:38:54,002 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:38:54,030 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:38:54,032 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:38:54,033 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:38:54,038 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]' failed with error: 
new(): invalid data type 'str'
2023-09-01 16:38:54,046 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:41:01,440 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:41:01,444 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:41:03,862 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:41:04,608 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:41:05,220 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:41:05,228 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:41:05,255 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:41:05,256 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:41:05,257 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:41:05,262 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]' failed with error: 
new(): invalid data type 'str'
2023-09-01 16:41:05,269 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:43:17,085 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:43:17,089 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:43:19,519 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:43:20,250 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:43:20,854 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:43:20,862 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:43:22,698 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:43:22,699 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:43:22,701 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:43:22,719 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 16:43:22,921 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 16:43:23,096 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 16:43:23,098 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 16:43:48,991 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:43:48,994 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:43:51,402 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:43:51,874 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:43:51,875 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:43:54,082 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:43:54,082 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:43:55,033 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6634430885314941
2023-09-01 16:44:34,934 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:44:34,938 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:44:37,347 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:44:37,815 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:44:37,817 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:44:40,051 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:44:40,051 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:44:40,766 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6683257818222046
2023-09-01 16:44:40,995 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 5.13 GiB already allocated; 52.69 MiB free; 5.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-09-01 16:44:40,999 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:44:54,438 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:44:54,442 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:44:56,867 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:44:57,335 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:44:57,337 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:44:59,618 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:44:59,618 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:45:00,351 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6838051676750183
2023-09-01 16:45:00,430 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 5.13 GiB already allocated; 52.69 MiB free; 5.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-09-01 16:45:00,433 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:45:11,758 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:45:11,762 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:45:14,370 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:45:14,864 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:45:14,866 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:45:17,141 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:45:17,141 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:45:17,860 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.746320366859436
2023-09-01 16:45:17,932 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 5.13 GiB already allocated; 52.69 MiB free; 5.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-09-01 16:45:17,936 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:45:34,571 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:45:34,576 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:45:37,146 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:45:37,638 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:45:37,640 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:45:39,877 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:45:39,877 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:45:40,577 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7204434275627136
2023-09-01 16:45:40,655 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 5.13 GiB already allocated; 52.69 MiB free; 5.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-09-01 16:45:40,659 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:46:16,205 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:46:16,209 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:46:18,618 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:46:19,085 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:46:19,087 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:46:21,344 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:46:21,344 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:46:22,051 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7559053301811218
2023-09-01 16:46:22,126 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 5.13 GiB already allocated; 52.69 MiB free; 5.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-09-01 16:46:22,129 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:46:34,177 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:46:34,181 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:46:36,591 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:46:37,057 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:46:37,059 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:46:39,318 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:46:39,319 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:46:40,024 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7107691764831543
2023-09-01 16:46:40,097 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 5.13 GiB already allocated; 52.69 MiB free; 5.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-09-01 16:46:40,100 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:47:46,218 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:47:46,222 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:47:48,653 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:47:49,387 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:47:49,997 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:47:50,004 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:47:51,855 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:47:51,856 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:47:51,863 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 16:47:52,066 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 16:47:52,243 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 16:47:52,244 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 16:47:55,485 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:47:55,489 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:47:57,932 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:47:58,404 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:47:58,405 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:48:00,644 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:48:00,644 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:48:01,281 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.709666907787323
2023-09-01 16:53:53,117 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:53:53,121 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:53:55,556 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:53:56,293 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:53:56,902 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:53:56,910 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:53:58,745 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:53:58,746 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:53:58,754 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 16:53:58,957 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 16:53:59,129 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 16:53:59,131 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 16:54:02,141 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:54:02,145 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:54:04,714 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:54:05,207 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:54:05,208 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:54:07,660 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,660 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,663 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,663 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:07,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 16:54:08,330 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6742596626281738
2023-09-01 16:55:04,362 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:55:04,367 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:55:06,962 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 16:55:07,720 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 16:55:08,342 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:55:08,350 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 16:55:10,285 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 16:55:10,287 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 16:55:10,295 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 16:55:10,507 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 16:55:10,693 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 16:55:10,695 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 16:55:13,420 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:55:13,424 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:55:15,919 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:55:16,427 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:55:16,429 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:55:17,362 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2023-09-01 16:55:17,364 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:55:23,722 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:55:23,726 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:55:26,132 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:55:26,605 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:55:26,607 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:55:27,512 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2023-09-01 16:55:27,515 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 16:58:15,632 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 16:58:15,636 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 16:58:18,227 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 16:58:18,799 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 16:58:18,801 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 16:58:19,740 - kedro.pipeline.node - ERROR - Node 'ze: train([x_dt,params:parameters]) -> None' failed with error: 
CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2023-09-01 16:58:19,743 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 17:00:41,852 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:00:41,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:00:44,481 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 17:00:45,015 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 17:00:45,017 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 17:00:47,252 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:00:47,253 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:00:47,903 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6968306303024292
2023-09-01 17:03:59,514 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:03:59,519 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:04:02,111 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 17:04:02,639 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 17:04:02,640 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 17:04:04,867 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:04:04,867 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:04:07,390 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6929987072944641
2023-09-01 17:05:32,862 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:05:32,867 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:05:49,021 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:05:49,025 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:05:51,616 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 17:05:52,360 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 17:05:52,983 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 17:05:52,991 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 17:05:54,907 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 17:05:54,908 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 17:05:54,916 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 17:05:55,126 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 17:05:55,306 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 17:05:55,307 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 17:05:59,250 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:05:59,254 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:06:01,852 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 17:06:02,370 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 17:06:02,372 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 17:06:04,774 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,775 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,777 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,777 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,777 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,777 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,777 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,777 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,778 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:04,778 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:06:07,385 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6873708367347717
2023-09-01 17:10:08,807 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:10:08,811 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:10:11,275 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 17:10:12,028 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 17:10:12,650 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 17:10:12,658 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 17:10:14,504 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 17:10:14,505 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 17:10:14,513 - kedro.io.data_catalog - INFO - Saving data to 'x_dt' (PickleDataSet)...
2023-09-01 17:10:14,723 - kedro.io.data_catalog - INFO - Saving data to 'y_dt' (PickleDataSet)...
2023-09-01 17:10:14,901 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 17:10:14,902 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 17:10:19,098 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 17:10:19,101 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 17:10:21,561 - kedro.io.data_catalog - INFO - Loading data from 'x_dt' (PickleDataSet)...
2023-09-01 17:10:22,042 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 17:10:22,044 - kedro.pipeline.node - INFO - Running node: ze: train([x_dt,params:parameters]) -> None
2023-09-01 17:10:24,475 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,475 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,477 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,478 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,477 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,477 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,478 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,478 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,478 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:24,479 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:10:27,152 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6970226764678955
2023-09-01 17:35:29,593 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,594 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,595 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,596 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,597 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,597 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,597 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,597 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,597 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,597 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 17:35:29,838 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.028217602521181107
2023-09-01 18:00:31,175 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,176 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,178 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,178 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,178 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,178 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 18:00:31,398 - granlp.pipelines.models.nodes - INFO - Epoch: 2, Loss:  0.012389245443046093
2023-09-01 19:35:20,505 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 19:35:20,509 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 19:35:22,945 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 19:35:23,691 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 19:35:24,307 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 19:35:24,314 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 19:35:26,211 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 19:35:26,212 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 19:35:26,213 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]' failed with error: 
name 'val_loader' is not defined
2023-09-01 19:35:26,221 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 19:35:50,549 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 19:35:50,553 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 19:35:59,443 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 19:35:59,447 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 19:36:01,866 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 19:36:02,600 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 19:36:03,209 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 19:36:03,217 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]
2023-09-01 19:36:05,123 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 19:36:05,124 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 19:36:05,125 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [x_dt,y_dt]' failed with error: 
name 'val_loader' is not defined
2023-09-01 19:36:05,133 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 19:39:43,080 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 19:39:43,084 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 19:39:45,488 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 19:39:46,224 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 19:39:46,839 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 19:39:46,847 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-01 19:39:46,848 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]' failed with error: 
local variable 'val_data' referenced before assignment
2023-09-01 19:39:46,856 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 19:42:58,179 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 19:42:58,182 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 19:43:00,627 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 19:43:01,369 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 19:43:01,981 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 19:43:01,989 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-01 19:43:03,849 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 19:43:03,850 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-01 19:43:03,851 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 19:43:03,859 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-01 19:43:04,046 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-01 19:43:04,084 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-01 19:43:04,244 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 19:43:04,246 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 20:36:09,750 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:36:09,754 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:36:46,851 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:36:46,854 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:38:21,886 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:38:21,889 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:38:48,216 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:38:48,220 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:39:50,513 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:39:50,517 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:39:52,961 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 20:39:53,703 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 20:39:54,312 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:39:54,319 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-01 20:39:54,503 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 20:39:54,504 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-01 20:39:54,505 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 20:39:54,515 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-01 20:39:54,548 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-01 20:39:54,560 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-01 20:39:54,727 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 20:39:54,728 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 20:40:13,931 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:40:13,935 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:40:16,407 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 20:40:17,157 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 20:40:17,769 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:40:17,776 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-01 20:40:17,961 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 20:40:17,963 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-01 20:40:17,964 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 20:40:17,973 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-01 20:40:17,997 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-01 20:40:18,007 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-01 20:40:18,175 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 20:40:18,176 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 20:40:24,621 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:40:24,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:40:27,048 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 20:40:27,082 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 20:40:27,098 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:40:27,100 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 20:40:29,476 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,477 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,477 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,478 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,479 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,480 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,492 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,485 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,492 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:29,492 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:40:32,089 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6844491362571716
2023-09-01 20:42:52,882 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,883 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,885 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,883 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:52,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,386 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,386 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,387 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,388 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,389 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,391 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,391 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,389 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,392 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,392 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:42:56,635 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.01592770591378212
2023-09-01 20:44:29,736 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:44:29,740 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:44:32,183 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 20:44:32,216 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 20:44:32,232 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:44:32,234 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 20:44:34,621 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,621 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,622 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,622 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,622 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,623 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,623 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,629 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,629 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:34,629 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:37,424 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
Caught OutOfMemoryError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/models/models/distilbert.py", line 20, in forward
    output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 609, in forward
    return self.transformer(
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 375, in forward
    layer_outputs = layer_module(
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 295, in forward
    sa_output = self.attention(
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 233, in forward
    context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.78 GiB total capacity; 5.05 GiB already allocated; 16.69 MiB free; 5.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2023-09-01 20:44:37,432 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 20:44:49,029 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:44:49,032 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:44:51,447 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 20:44:51,480 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 20:44:51,497 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:44:51,499 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 20:44:53,881 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,881 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,882 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,884 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,887 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,887 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:53,887 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:44:56,496 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7075578570365906
2023-09-01 20:47:12,438 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,441 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:47:12,440 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,652 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,655 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,652 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,653 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,653 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,653 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,653 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,653 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,653 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,652 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:01,866 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.12595808506011963
2023-09-01 20:48:10,468 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:48:10,472 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:48:17,300 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:48:17,304 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:48:19,901 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 20:48:19,936 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 20:48:19,953 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:48:19,954 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,371 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:22,373 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:48:25,021 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7051630020141602
2023-09-01 20:50:40,868 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,869 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:50:40,872 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:51:29,549 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
name 'np' is not defined
2023-09-01 20:51:29,554 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 20:52:20,697 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:52:20,701 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:52:39,731 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:52:39,734 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:52:42,148 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 20:52:42,181 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 20:52:42,198 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:52:42,199 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 20:52:44,557 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,557 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,558 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,558 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,559 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,559 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,565 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,565 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,565 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:44,565 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:52:47,178 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6915993690490723
2023-09-01 20:55:02,698 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,698 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,698 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,698 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,700 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,700 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,704 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:55:02,936 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
'targets'
2023-09-01 20:55:02,943 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 20:57:20,663 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:57:20,666 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:57:23,242 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-01 20:57:23,988 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-01 20:57:24,595 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:57:24,602 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-01 20:57:24,805 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-01 20:57:24,806 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-01 20:57:24,807 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-01 20:57:24,817 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-01 20:57:24,840 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-01 20:57:24,851 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-01 20:57:25,021 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-01 20:57:25,023 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-01 20:57:39,798 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 20:57:39,802 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 20:57:42,415 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 20:57:42,451 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 20:57:42,469 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 20:57:42,470 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,856 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:44,857 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 20:57:47,559 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6811960935592651
2023-09-01 21:00:03,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,248 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,247 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,250 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:03,251 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:00:08,875 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
name 'iterator' is not defined
2023-09-01 21:00:08,878 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-01 21:01:22,064 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-01 21:01:22,067 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-01 21:01:24,647 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-01 21:01:24,683 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-01 21:01:24,701 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-01 21:01:24,703 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-01 21:01:27,102 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,103 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,104 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,105 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,105 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,105 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,105 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,105 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:27,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:01:29,714 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6656559705734253
2023-09-01 21:03:45,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,250 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,249 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,256 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,255 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,252 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,256 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,254 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:45,256 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,280 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,280 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,282 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,286 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,286 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,282 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,286 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,288 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,288 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,287 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-01 21:03:51,523 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.011327939108014107
2023-09-02 16:42:56,376 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 16:42:56,380 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 16:42:58,818 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 16:42:58,851 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 16:42:58,869 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 16:42:58,871 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 16:43:01,296 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,296 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,297 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,298 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,298 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,298 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,298 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,304 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,304 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:01,304 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:43:03,980 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6860030889511108
2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,961 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:24,965 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 16:45:30,522 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
Classification metrics can't handle a mix of binary and continuous targets
2023-09-02 16:45:30,526 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-02 17:53:18,806 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 17:53:18,809 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 17:53:21,284 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 17:53:21,317 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 17:53:21,336 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 17:53:21,337 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 17:53:38,661 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 17:53:38,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 17:53:41,096 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 17:53:41,129 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 17:53:41,147 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 17:53:41,148 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 17:53:43,505 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,505 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,506 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,506 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,506 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,514 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,508 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,514 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:43,514 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:53:46,141 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6877879500389099
2023-09-02 17:56:08,506 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,506 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,507 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:08,512 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,081 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 17:56:14,088 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 17:56:14,667 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,667 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,668 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,668 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,669 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,669 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,669 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,670 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,670 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,674 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:56:14,903 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.02089877799153328
2023-09-02 17:58:30,608 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,608 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,610 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:30,614 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,170 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 17:58:36,179 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 17:58:36,184 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 17:58:36,766 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,771 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 17:58:36,993 - granlp.pipelines.models.nodes - INFO - Epoch: 2, Loss:  0.06078829616308212
2023-09-02 18:00:00,559 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 18:00:00,562 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 18:00:03,051 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-02 18:00:03,794 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-02 18:00:04,411 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 18:00:04,419 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-02 18:00:06,301 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-02 18:00:06,303 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-02 18:00:06,304 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-02 18:00:06,311 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-02 18:00:06,488 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-02 18:00:06,517 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-02 18:00:06,696 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-02 18:00:06,698 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-02 18:40:36,801 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 18:40:36,804 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 18:40:39,241 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 18:40:39,565 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 18:40:39,724 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 18:40:39,726 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 18:40:42,132 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,132 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,134 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,134 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,135 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,134 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,134 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,135 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,135 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:42,135 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 18:40:44,759 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6454262733459473
2023-09-02 19:03:19,747 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,746 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,746 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,746 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,747 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,747 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,747 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,748 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,748 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:03:19,757 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:13,720 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 19:04:14,414 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,414 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,414 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,416 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,416 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,417 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,417 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,417 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,417 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,417 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:04:14,638 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.05187968164682388
2023-09-02 19:26:44,347 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,347 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,348 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,348 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,349 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,349 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,349 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,350 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,354 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:26:44,350 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,831 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,831 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,832 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,834 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,833 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,834 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,833 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,841 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,841 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:38,841 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:27:39,045 - granlp.pipelines.models.nodes - INFO - Epoch: 2, Loss:  0.025632111355662346
2023-09-02 19:50:06,806 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,807 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,807 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,807 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,808 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,809 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,808 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,809 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,814 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:50:06,809 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:00,544 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 19:51:01,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,107 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,107 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,107 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,107 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,106 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,108 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,108 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 19:51:01,329 - granlp.pipelines.models.nodes - INFO - Epoch: 3, Loss:  0.02464599534869194
2023-09-02 20:13:28,075 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,075 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,076 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,074 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,076 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,077 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,075 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,076 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,079 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:13:28,084 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,091 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 20:14:22,657 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,658 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,658 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,658 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,661 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,657 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:14:22,944 - granlp.pipelines.models.nodes - INFO - Epoch: 4, Loss:  0.033508699387311935
2023-09-02 20:36:49,227 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,229 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,229 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,229 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,229 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,229 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,229 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:36:49,235 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,247 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,247 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,248 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,247 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,248 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,251 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,251 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,255 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,255 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,255 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:37:43,462 - granlp.pipelines.models.nodes - INFO - Epoch: 5, Loss:  0.00798126496374607
2023-09-02 20:49:24,467 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 20:49:24,471 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 20:49:26,888 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 20:49:27,210 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 20:49:27,369 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 20:49:27,370 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 20:49:31,782 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 20:49:31,786 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 20:49:34,195 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-02 20:49:34,932 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-02 20:49:35,540 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 20:49:35,547 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-02 20:49:35,672 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-02 20:49:35,673 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-02 20:49:35,674 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-02 20:49:35,684 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-02 20:49:35,711 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-02 20:49:35,723 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-02 20:49:35,891 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-02 20:49:35,893 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-02 20:53:21,346 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 20:53:21,350 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 20:53:23,768 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 20:53:23,795 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 20:53:23,812 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 20:53:23,813 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 20:53:31,295 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 20:53:31,299 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 20:53:33,724 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 20:53:33,751 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 20:53:33,768 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 20:53:33,769 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 20:53:36,158 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,158 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,158 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,159 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,159 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,159 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,159 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,160 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,160 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:36,163 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:53:38,815 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7034351825714111
2023-09-02 20:54:46,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,698 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,698 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,705 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,706 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,707 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,707 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:46,707 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 20:54:49,539 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
name 'criterion' is not defined
2023-09-02 20:54:49,542 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-02 21:06:28,063 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 21:06:28,067 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 21:07:14,472 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 21:07:14,476 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 21:07:17,051 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 21:07:17,079 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 21:07:17,096 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 21:07:17,098 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 21:07:19,514 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,514 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:19,519 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:07:22,173 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6554262638092041
2023-09-02 21:08:37,907 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,906 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,908 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,907 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,908 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,907 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,907 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,911 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,907 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:37,908 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:08:41,231 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
Parent directory outputs does not exist.
2023-09-02 21:08:41,233 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-02 21:11:47,725 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 21:11:47,729 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 21:11:56,752 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 21:11:56,756 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 21:11:59,163 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 21:11:59,189 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 21:11:59,206 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 21:11:59,207 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 21:12:01,575 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,575 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,576 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,576 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,576 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,576 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,578 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,580 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,578 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:01,578 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:12:04,191 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6921891570091248
2023-09-02 21:13:12,038 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,043 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,043 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,039 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,042 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,038 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,042 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,048 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,038 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:12,048 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:13:16,074 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:13:16,080 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:13:16,082 - kedro.pipeline.node - ERROR - Node 'ze: train([train_dt,val_dt,params:parameters]) -> None' failed with error: 
name 'accuracy' is not defined
2023-09-02 21:13:16,083 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-02 21:14:38,864 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-02 21:14:38,867 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-02 21:14:41,269 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-02 21:14:41,295 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-02 21:14:41,312 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-02 21:14:41,313 - kedro.pipeline.node - INFO - Running node: ze: train([train_dt,val_dt,params:parameters]) -> None
2023-09-02 21:14:43,677 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,678 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,679 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,683 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,679 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,680 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,679 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,680 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,680 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:43,680 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:14:46,325 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.6585174202919006
2023-09-02 21:15:54,088 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,088 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,090 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,090 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,091 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,091 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,091 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,092 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,091 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:54,091 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:58,423 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:15:58,430 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:15:59,019 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,020 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,020 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,020 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,021 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,021 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,020 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,023 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,022 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,025 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:15:59,235 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.008853334002196789
2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:06,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,128 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:17:11,135 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:17:11,659 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,659 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,665 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:17:11,884 - granlp.pipelines.models.nodes - INFO - Epoch: 2, Loss:  0.047231175005435944
2023-09-02 21:18:19,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,622 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,629 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:19,625 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,512 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:18:22,519 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:18:22,969 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,970 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,970 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,970 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,970 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,970 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,971 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,971 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,972 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:22,975 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:18:23,207 - granlp.pipelines.models.nodes - INFO - Epoch: 3, Loss:  0.05878305435180664
2023-09-02 21:19:31,291 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,292 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,292 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,292 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,293 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,292 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,292 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,292 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,296 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:31,293 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,194 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:19:34,201 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:19:34,788 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,789 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,790 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:34,791 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:19:35,041 - granlp.pipelines.models.nodes - INFO - Epoch: 4, Loss:  0.008219599723815918
2023-09-02 21:20:43,225 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,230 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,227 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,234 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,227 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:43,228 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,183 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:20:46,190 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:20:46,720 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,720 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,721 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,722 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,725 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,725 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,725 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,725 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,724 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,726 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:20:46,969 - granlp.pipelines.models.nodes - INFO - Epoch: 5, Loss:  0.09041160345077515
2023-09-02 21:21:54,941 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,944 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,939 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,941 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,944 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,941 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,945 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,939 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,941 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:54,944 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,313 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,313 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,313 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,313 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,313 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,314 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,315 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,314 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,315 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,318 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:21:58,594 - granlp.pipelines.models.nodes - INFO - Epoch: 6, Loss:  0.031869977712631226
2023-09-02 21:23:06,622 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,624 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:06,627 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:09,509 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:23:10,031 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,031 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,031 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,034 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,034 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,034 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,034 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,035 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,035 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,037 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:23:10,262 - granlp.pipelines.models.nodes - INFO - Epoch: 7, Loss:  0.003314034081995487
2023-09-02 21:24:18,050 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,050 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,049 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,050 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,049 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,050 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,049 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,050 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,054 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:18,056 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:20,955 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-02 21:24:21,488 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,487 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,488 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,488 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,490 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,494 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,494 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,494 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,494 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,495 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:24:21,699 - granlp.pipelines.models.nodes - INFO - Epoch: 8, Loss:  0.005833315663039684
2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:29,697 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,179 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,184 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:25:33,411 - granlp.pipelines.models.nodes - INFO - Epoch: 9, Loss:  0.008799342438578606
2023-09-02 21:26:41,207 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:41,203 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-02 21:26:44,323 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-02 21:26:44,327 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 15:33:59,717 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:33:59,721 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:36:46,954 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:36:46,957 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:38:53,277 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:38:53,281 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:39:18,764 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:39:18,768 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:39:29,820 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:39:29,824 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:39:41,071 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:39:41,074 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:39:43,483 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:39:43,610 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:39:43,612 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:39:43,613 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
name 'model' is not defined
2023-09-03 15:39:43,616 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:40:05,721 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:40:05,726 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:40:08,207 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:40:08,332 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:40:08,334 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:40:08,336 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
name 'model' is not defined
2023-09-03 15:40:08,338 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:40:29,255 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:40:29,259 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:40:31,820 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:40:31,946 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:40:31,948 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:40:31,950 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
name 'model' is not defined
2023-09-03 15:40:31,952 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:41:36,124 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:41:36,128 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:41:38,698 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:41:38,823 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:41:38,824 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:41:38,826 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
name 'DistilBERTClass' is not defined
2023-09-03 15:41:38,829 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:43:21,206 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:43:21,210 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:43:23,790 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:43:23,916 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:43:23,917 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:43:24,679 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
Expected state_dict to be dict-like, got <class 'str'>.
2023-09-03 15:43:24,682 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:45:15,965 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:45:15,969 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:45:18,571 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:45:18,697 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:45:18,699 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:45:21,420 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
Error(s) in loading state_dict for DataParallel:
	Missing key(s) in state_dict: "module.l1.embeddings.word_embeddings.weight", "module.l1.embeddings.position_embeddings.weight", "module.l1.embeddings.LayerNorm.weight", "module.l1.embeddings.LayerNorm.bias", "module.l1.transformer.layer.0.attention.q_lin.weight", "module.l1.transformer.layer.0.attention.q_lin.bias", "module.l1.transformer.layer.0.attention.k_lin.weight", "module.l1.transformer.layer.0.attention.k_lin.bias", "module.l1.transformer.layer.0.attention.v_lin.weight", "module.l1.transformer.layer.0.attention.v_lin.bias", "module.l1.transformer.layer.0.attention.out_lin.weight", "module.l1.transformer.layer.0.attention.out_lin.bias", "module.l1.transformer.layer.0.sa_layer_norm.weight", "module.l1.transformer.layer.0.sa_layer_norm.bias", "module.l1.transformer.layer.0.ffn.lin1.weight", "module.l1.transformer.layer.0.ffn.lin1.bias", "module.l1.transformer.layer.0.ffn.lin2.weight", "module.l1.transformer.layer.0.ffn.lin2.bias", "module.l1.transformer.layer.0.output_layer_norm.weight", "module.l1.transformer.layer.0.output_layer_norm.bias", "module.l1.transformer.layer.1.attention.q_lin.weight", "module.l1.transformer.layer.1.attention.q_lin.bias", "module.l1.transformer.layer.1.attention.k_lin.weight", "module.l1.transformer.layer.1.attention.k_lin.bias", "module.l1.transformer.layer.1.attention.v_lin.weight", "module.l1.transformer.layer.1.attention.v_lin.bias", "module.l1.transformer.layer.1.attention.out_lin.weight", "module.l1.transformer.layer.1.attention.out_lin.bias", "module.l1.transformer.layer.1.sa_layer_norm.weight", "module.l1.transformer.layer.1.sa_layer_norm.bias", "module.l1.transformer.layer.1.ffn.lin1.weight", "module.l1.transformer.layer.1.ffn.lin1.bias", "module.l1.transformer.layer.1.ffn.lin2.weight", "module.l1.transformer.layer.1.ffn.lin2.bias", "module.l1.transformer.layer.1.output_layer_norm.weight", "module.l1.transformer.layer.1.output_layer_norm.bias", "module.l1.transformer.layer.2.attention.q_lin.weight", "module.l1.transformer.layer.2.attention.q_lin.bias", "module.l1.transformer.layer.2.attention.k_lin.weight", "module.l1.transformer.layer.2.attention.k_lin.bias", "module.l1.transformer.layer.2.attention.v_lin.weight", "module.l1.transformer.layer.2.attention.v_lin.bias", "module.l1.transformer.layer.2.attention.out_lin.weight", "module.l1.transformer.layer.2.attention.out_lin.bias", "module.l1.transformer.layer.2.sa_layer_norm.weight", "module.l1.transformer.layer.2.sa_layer_norm.bias", "module.l1.transformer.layer.2.ffn.lin1.weight", "module.l1.transformer.layer.2.ffn.lin1.bias", "module.l1.transformer.layer.2.ffn.lin2.weight", "module.l1.transformer.layer.2.ffn.lin2.bias", "module.l1.transformer.layer.2.output_layer_norm.weight", "module.l1.transformer.layer.2.output_layer_norm.bias", "module.l1.transformer.layer.3.attention.q_lin.weight", "module.l1.transformer.layer.3.attention.q_lin.bias", "module.l1.transformer.layer.3.attention.k_lin.weight", "module.l1.transformer.layer.3.attention.k_lin.bias", "module.l1.transformer.layer.3.attention.v_lin.weight", "module.l1.transformer.layer.3.attention.v_lin.bias", "module.l1.transformer.layer.3.attention.out_lin.weight", "module.l1.transformer.layer.3.attention.out_lin.bias", "module.l1.transformer.layer.3.sa_layer_norm.weight", "module.l1.transformer.layer.3.sa_layer_norm.bias", "module.l1.transformer.layer.3.ffn.lin1.weight", "module.l1.transformer.layer.3.ffn.lin1.bias", "module.l1.transformer.layer.3.ffn.lin2.weight", "module.l1.transformer.layer.3.ffn.lin2.bias", "module.l1.transformer.layer.3.output_layer_norm.weight", "module.l1.transformer.layer.3.output_layer_norm.bias", "module.l1.transformer.layer.4.attention.q_lin.weight", "module.l1.transformer.layer.4.attention.q_lin.bias", "module.l1.transformer.layer.4.attention.k_lin.weight", "module.l1.transformer.layer.4.attention.k_lin.bias", "module.l1.transformer.layer.4.attention.v_lin.weight", "module.l1.transformer.layer.4.attention.v_lin.bias", "module.l1.transformer.layer.4.attention.out_lin.weight", "module.l1.transformer.layer.4.attention.out_lin.bias", "module.l1.transformer.layer.4.sa_layer_norm.weight", "module.l1.transformer.layer.4.sa_layer_norm.bias", "module.l1.transformer.layer.4.ffn.lin1.weight", "module.l1.transformer.layer.4.ffn.lin1.bias", "module.l1.transformer.layer.4.ffn.lin2.weight", "module.l1.transformer.layer.4.ffn.lin2.bias", "module.l1.transformer.layer.4.output_layer_norm.weight", "module.l1.transformer.layer.4.output_layer_norm.bias", "module.l1.transformer.layer.5.attention.q_lin.weight", "module.l1.transformer.layer.5.attention.q_lin.bias", "module.l1.transformer.layer.5.attention.k_lin.weight", "module.l1.transformer.layer.5.attention.k_lin.bias", "module.l1.transformer.layer.5.attention.v_lin.weight", "module.l1.transformer.layer.5.attention.v_lin.bias", "module.l1.transformer.layer.5.attention.out_lin.weight", "module.l1.transformer.layer.5.attention.out_lin.bias", "module.l1.transformer.layer.5.sa_layer_norm.weight", "module.l1.transformer.layer.5.sa_layer_norm.bias", "module.l1.transformer.layer.5.ffn.lin1.weight", "module.l1.transformer.layer.5.ffn.lin1.bias", "module.l1.transformer.layer.5.ffn.lin2.weight", "module.l1.transformer.layer.5.ffn.lin2.bias", "module.l1.transformer.layer.5.output_layer_norm.weight", "module.l1.transformer.layer.5.output_layer_norm.bias", "module.pre_classifier.weight", "module.pre_classifier.bias", "module.classifier.weight", "module.classifier.bias". 
	Unexpected key(s) in state_dict: "epoch", "model_state_dict", "optimizer_state_dict". 
2023-09-03 15:45:21,435 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:46:31,590 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:46:31,593 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:46:34,177 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:46:34,302 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:46:34,303 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:46:37,006 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
'dict' object has no attribute 'to'
2023-09-03 15:46:37,008 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:47:38,275 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:47:38,279 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:47:40,853 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:47:40,977 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:47:40,979 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:47:43,657 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
Error(s) in loading state_dict for DataParallel:
	Missing key(s) in state_dict: "module.l1.embeddings.word_embeddings.weight", "module.l1.embeddings.position_embeddings.weight", "module.l1.embeddings.LayerNorm.weight", "module.l1.embeddings.LayerNorm.bias", "module.l1.transformer.layer.0.attention.q_lin.weight", "module.l1.transformer.layer.0.attention.q_lin.bias", "module.l1.transformer.layer.0.attention.k_lin.weight", "module.l1.transformer.layer.0.attention.k_lin.bias", "module.l1.transformer.layer.0.attention.v_lin.weight", "module.l1.transformer.layer.0.attention.v_lin.bias", "module.l1.transformer.layer.0.attention.out_lin.weight", "module.l1.transformer.layer.0.attention.out_lin.bias", "module.l1.transformer.layer.0.sa_layer_norm.weight", "module.l1.transformer.layer.0.sa_layer_norm.bias", "module.l1.transformer.layer.0.ffn.lin1.weight", "module.l1.transformer.layer.0.ffn.lin1.bias", "module.l1.transformer.layer.0.ffn.lin2.weight", "module.l1.transformer.layer.0.ffn.lin2.bias", "module.l1.transformer.layer.0.output_layer_norm.weight", "module.l1.transformer.layer.0.output_layer_norm.bias", "module.l1.transformer.layer.1.attention.q_lin.weight", "module.l1.transformer.layer.1.attention.q_lin.bias", "module.l1.transformer.layer.1.attention.k_lin.weight", "module.l1.transformer.layer.1.attention.k_lin.bias", "module.l1.transformer.layer.1.attention.v_lin.weight", "module.l1.transformer.layer.1.attention.v_lin.bias", "module.l1.transformer.layer.1.attention.out_lin.weight", "module.l1.transformer.layer.1.attention.out_lin.bias", "module.l1.transformer.layer.1.sa_layer_norm.weight", "module.l1.transformer.layer.1.sa_layer_norm.bias", "module.l1.transformer.layer.1.ffn.lin1.weight", "module.l1.transformer.layer.1.ffn.lin1.bias", "module.l1.transformer.layer.1.ffn.lin2.weight", "module.l1.transformer.layer.1.ffn.lin2.bias", "module.l1.transformer.layer.1.output_layer_norm.weight", "module.l1.transformer.layer.1.output_layer_norm.bias", "module.l1.transformer.layer.2.attention.q_lin.weight", "module.l1.transformer.layer.2.attention.q_lin.bias", "module.l1.transformer.layer.2.attention.k_lin.weight", "module.l1.transformer.layer.2.attention.k_lin.bias", "module.l1.transformer.layer.2.attention.v_lin.weight", "module.l1.transformer.layer.2.attention.v_lin.bias", "module.l1.transformer.layer.2.attention.out_lin.weight", "module.l1.transformer.layer.2.attention.out_lin.bias", "module.l1.transformer.layer.2.sa_layer_norm.weight", "module.l1.transformer.layer.2.sa_layer_norm.bias", "module.l1.transformer.layer.2.ffn.lin1.weight", "module.l1.transformer.layer.2.ffn.lin1.bias", "module.l1.transformer.layer.2.ffn.lin2.weight", "module.l1.transformer.layer.2.ffn.lin2.bias", "module.l1.transformer.layer.2.output_layer_norm.weight", "module.l1.transformer.layer.2.output_layer_norm.bias", "module.l1.transformer.layer.3.attention.q_lin.weight", "module.l1.transformer.layer.3.attention.q_lin.bias", "module.l1.transformer.layer.3.attention.k_lin.weight", "module.l1.transformer.layer.3.attention.k_lin.bias", "module.l1.transformer.layer.3.attention.v_lin.weight", "module.l1.transformer.layer.3.attention.v_lin.bias", "module.l1.transformer.layer.3.attention.out_lin.weight", "module.l1.transformer.layer.3.attention.out_lin.bias", "module.l1.transformer.layer.3.sa_layer_norm.weight", "module.l1.transformer.layer.3.sa_layer_norm.bias", "module.l1.transformer.layer.3.ffn.lin1.weight", "module.l1.transformer.layer.3.ffn.lin1.bias", "module.l1.transformer.layer.3.ffn.lin2.weight", "module.l1.transformer.layer.3.ffn.lin2.bias", "module.l1.transformer.layer.3.output_layer_norm.weight", "module.l1.transformer.layer.3.output_layer_norm.bias", "module.l1.transformer.layer.4.attention.q_lin.weight", "module.l1.transformer.layer.4.attention.q_lin.bias", "module.l1.transformer.layer.4.attention.k_lin.weight", "module.l1.transformer.layer.4.attention.k_lin.bias", "module.l1.transformer.layer.4.attention.v_lin.weight", "module.l1.transformer.layer.4.attention.v_lin.bias", "module.l1.transformer.layer.4.attention.out_lin.weight", "module.l1.transformer.layer.4.attention.out_lin.bias", "module.l1.transformer.layer.4.sa_layer_norm.weight", "module.l1.transformer.layer.4.sa_layer_norm.bias", "module.l1.transformer.layer.4.ffn.lin1.weight", "module.l1.transformer.layer.4.ffn.lin1.bias", "module.l1.transformer.layer.4.ffn.lin2.weight", "module.l1.transformer.layer.4.ffn.lin2.bias", "module.l1.transformer.layer.4.output_layer_norm.weight", "module.l1.transformer.layer.4.output_layer_norm.bias", "module.l1.transformer.layer.5.attention.q_lin.weight", "module.l1.transformer.layer.5.attention.q_lin.bias", "module.l1.transformer.layer.5.attention.k_lin.weight", "module.l1.transformer.layer.5.attention.k_lin.bias", "module.l1.transformer.layer.5.attention.v_lin.weight", "module.l1.transformer.layer.5.attention.v_lin.bias", "module.l1.transformer.layer.5.attention.out_lin.weight", "module.l1.transformer.layer.5.attention.out_lin.bias", "module.l1.transformer.layer.5.sa_layer_norm.weight", "module.l1.transformer.layer.5.sa_layer_norm.bias", "module.l1.transformer.layer.5.ffn.lin1.weight", "module.l1.transformer.layer.5.ffn.lin1.bias", "module.l1.transformer.layer.5.ffn.lin2.weight", "module.l1.transformer.layer.5.ffn.lin2.bias", "module.l1.transformer.layer.5.output_layer_norm.weight", "module.l1.transformer.layer.5.output_layer_norm.bias", "module.pre_classifier.weight", "module.pre_classifier.bias", "module.classifier.weight", "module.classifier.bias". 
	Unexpected key(s) in state_dict: "epoch", "model_state_dict", "optimizer_state_dict". 
2023-09-03 15:47:43,672 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:49:18,487 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:49:18,490 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:49:21,088 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:49:21,214 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:49:21,216 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:49:24,039 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
name 'tqdm' is not defined
2023-09-03 15:49:24,041 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:49:42,534 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:49:42,538 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:49:45,127 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:49:45,251 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:49:45,253 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:49:53,561 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:49:53,565 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:49:55,978 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:49:56,103 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:49:56,104 - kedro.pipeline.node - INFO - Running node: ze: eval([test_dt,params:parameters]) -> [submission]
2023-09-03 15:49:58,949 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_dt,params:parameters]) -> [submission]' failed with error: 
name 'test_loader' is not defined
2023-09-03 15:49:58,950 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:51:28,790 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:51:28,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:51:31,359 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 15:51:31,979 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:51:32,104 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:51:32,109 - kedro.pipeline.node - INFO - Running node: ze: eval([test_comments_processed,test_dt,params:parameters]) -> [submission]
2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,243 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,239 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:35,459 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_comments_processed,test_dt,params:parameters]) -> [submission]' failed with error: 
name 'device' is not defined
2023-09-03 15:51:35,467 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 15:51:50,346 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 15:51:50,350 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 15:51:52,928 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 15:51:53,549 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 15:51:53,675 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 15:51:53,680 - kedro.pipeline.node - INFO - Running node: ze: eval([test_comments_processed,test_dt,params:parameters]) -> [submission]
2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,796 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 15:51:56,793 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 16:00:32,726 - kedro.io.data_catalog - INFO - Saving data to 'submission' (CSVDataSet)...
2023-09-03 16:00:33,606 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 16:00:33,610 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 17:41:08,244 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 17:41:08,248 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 17:41:10,776 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 17:41:11,507 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 17:41:12,114 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 17:41:12,122 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-03 17:41:14,052 - granlp.pipelines.build_graph.nodes - INFO - Loading Training set
2023-09-03 17:41:14,054 - granlp.pipelines.build_graph.nodes - INFO - Loading val set
2023-09-03 17:41:14,055 - granlp.pipelines.build_graph.nodes - INFO - Loading Test set
2023-09-03 17:41:14,063 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-03 17:41:14,244 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-03 17:41:14,272 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-03 17:41:14,451 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 17:41:14,453 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 17:42:25,661 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 17:42:25,665 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 17:42:28,260 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 17:42:28,636 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 17:42:28,818 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 17:42:28,820 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,params:parameters]) -> None
2023-09-03 17:42:31,213 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,213 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,214 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,215 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,215 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,215 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,215 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,215 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,216 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:31,216 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 17:42:33,838 - granlp.pipelines.models.nodes - INFO - Epoch: 0, Loss:  0.7097705602645874
2023-09-03 18:05:24,679 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,679 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,680 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,681 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,680 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,681 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,681 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,681 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,686 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:05:24,681 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:19,976 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 18:06:19,993 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 18:06:20,662 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,664 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,665 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,666 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,666 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,666 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,666 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,666 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:06:20,895 - granlp.pipelines.models.nodes - INFO - Epoch: 1, Loss:  0.061606019735336304
2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,785 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:29:05,790 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,751 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,752 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,751 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,751 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,751 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,751 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,752 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,752 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,752 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,752 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:30:01,999 - granlp.pipelines.models.nodes - INFO - Epoch: 2, Loss:  0.026873549446463585
2023-09-03 18:52:45,452 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,452 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,454 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,454 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,454 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,453 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,454 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,454 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,454 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:52:45,461 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,117 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 18:53:39,691 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,692 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,695 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,696 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,696 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,696 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,697 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 18:53:39,883 - granlp.pipelines.models.nodes - INFO - Epoch: 3, Loss:  0.015497597865760326
2023-09-03 19:02:43,460 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:02:43,464 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:03:58,896 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:03:58,900 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:04:01,485 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 19:04:02,108 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 19:04:02,235 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 19:04:02,240 - kedro.pipeline.node - INFO - Running node: ze: eval([test_comments_processed,test_dt,params:parameters]) -> [submission]
2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,333 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,334 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:04:05,340 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:12:31,486 - kedro.pipeline.node - ERROR - Node 'ze: eval([test_comments_processed,test_dt,params:parameters]) -> [submission]' failed with error: 
'id'
2023-09-03 19:12:31,491 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 19:34:50,046 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:34:50,049 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:41:03,626 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:41:03,630 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:41:24,484 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:41:24,487 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:41:47,921 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:41:47,925 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:43:11,372 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:43:11,375 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:43:30,923 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:43:30,926 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:43:33,492 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-09-03 19:43:33,495 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 19:45:02,496 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:45:02,500 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:45:04,952 - kedro.io.data_catalog - INFO - Loading data from 'train_comments' (CSVDataSet)...
2023-09-03 19:45:05,778 - kedro.pipeline.node - INFO - Running node: zebi: preprocess_train([train_comments]) -> [train_comments_processed]
2023-09-03 19:45:21,587 - granlp.pipelines.preprocessing.nodes - INFO - HEAD OF TESTING DATA:
2023-09-03 19:45:21,594 - granlp.pipelines.preprocessing.nodes - INFO - Our Labels: []
2023-09-03 19:45:21,595 - granlp.pipelines.preprocessing.nodes - INFO - The shape of our labels: (159571,)
2023-09-03 19:45:21,897 - kedro.io.data_catalog - INFO - Saving data to 'train_comments_processed' (CSVDataSet)...
2023-09-03 19:45:23,218 - kedro.runner.sequential_runner - INFO - Completed 1 out of 2 tasks
2023-09-03 19:45:23,220 - kedro.io.data_catalog - INFO - Loading data from 'test_comments' (CSVDataSet)...
2023-09-03 19:45:23,891 - kedro.pipeline.node - INFO - Running node: zebi2: preprocess_test([test_comments]) -> [test_comments_processed]
2023-09-03 19:45:35,874 - granlp.pipelines.preprocessing.nodes - INFO - HEAD OF TESTING DATA:
2023-09-03 19:45:35,880 - granlp.pipelines.preprocessing.nodes - INFO - The shape of our labels: (153164,)
2023-09-03 19:45:35,892 - kedro.io.data_catalog - INFO - Saving data to 'test_comments_processed' (CSVDataSet)...
2023-09-03 19:45:37,035 - kedro.runner.sequential_runner - INFO - Completed 2 out of 2 tasks
2023-09-03 19:45:37,036 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 19:50:32,777 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 19:50:32,780 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 19:50:35,145 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 19:50:35,831 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 19:50:35,960 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 19:50:35,966 - kedro.pipeline.node - INFO - Running node: ze: eval([test_comments_processed,test_dt,params:parameters]) -> [submission]
2023-09-03 19:50:38,990 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,990 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,992 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:50:38,996 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(

2023-09-03 19:59:11,951 - kedro.io.data_catalog - INFO - Saving data to 'submission' (CSVDataSet)...
2023-09-03 19:59:12,935 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 19:59:12,939 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 20:19:16,232 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 20:19:16,236 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 20:19:18,597 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 20:19:19,299 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 20:19:19,954 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 20:19:19,962 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-03 20:19:19,964 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]' failed with error: 
Failed to save outputs of node zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt].
The node definition contains a list of outputs ['train_dt', 'val_dt', 'test_dt'], whereas the node function returned a 'NoneType'.
2023-09-03 20:19:19,972 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 20:21:16,929 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 20:21:16,933 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 20:21:19,496 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 20:21:20,194 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 20:21:20,854 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 20:21:20,863 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-03 20:21:20,864 - granlp.pipelines.build_graph.nodes - INFO - Model chosen : Tfid+Logreg
2023-09-03 20:21:30,816 - kedro.pipeline.node - ERROR - Node 'zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]' failed with error: 
name 'text_X_dtm' is not defined
2023-09-03 20:21:30,832 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 20:22:16,808 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 20:22:16,811 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 20:22:19,180 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 20:22:19,873 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 20:22:20,526 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 20:22:20,534 - kedro.pipeline.node - INFO - Running node: zeb: build_graph([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-03 20:22:20,535 - granlp.pipelines.build_graph.nodes - INFO - Model chosen : Tfid+Logreg
2023-09-03 20:22:30,565 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-03 20:22:30,631 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-03 20:22:30,647 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-03 20:22:30,771 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 20:22:30,772 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 21:01:07,644 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:01:07,648 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:01:10,187 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:01:10,279 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:01:10,281 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:01:10,355 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:01:10,356 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,params:parameters]) -> None
2023-09-03 21:01:10,358 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,params:parameters]) -> None' failed with error: 
'csr_matrix' object has no attribute 'labels'
2023-09-03 21:01:10,360 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:27:12,241 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:27:12,244 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:27:30,681 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:27:30,685 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:27:33,211 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:27:33,303 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:27:33,305 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:27:33,378 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:27:34,062 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:27:34,723 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:27:34,732 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:27:34,734 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 21:27:34,742 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:27:51,486 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:27:51,490 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:27:54,052 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:27:54,141 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:27:54,143 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:27:54,216 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:27:54,897 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:27:55,563 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:27:55,571 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:27:55,573 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 21:27:55,581 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:29:24,230 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:29:24,233 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:29:26,777 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:29:26,867 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:29:26,869 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:29:26,941 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:29:27,623 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:29:28,288 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:29:28,296 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:29:28,298 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
literal_eval() missing 1 required positional argument: 'node_or_string'
2023-09-03 21:29:28,306 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:30:51,570 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:30:51,574 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:30:54,185 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:30:54,275 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:30:54,277 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:30:54,348 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:30:55,036 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:30:55,703 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:30:55,711 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:30:57,577 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 21:30:57,586 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:31:28,844 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:31:28,847 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:31:31,434 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:31:31,524 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:31:31,525 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:31:31,595 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:31:32,275 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:31:32,938 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:31:32,947 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:31:34,808 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 21:31:34,819 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:31:57,161 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:31:57,164 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:31:59,755 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:31:59,845 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:31:59,847 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:31:59,919 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:32:00,599 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:32:01,264 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:32:01,272 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:32:03,141 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 21:32:03,152 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:33:26,552 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:33:26,555 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:33:29,140 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:33:29,229 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:33:29,231 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:33:29,303 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:33:29,988 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:33:30,649 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:33:30,658 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:33:32,607 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 21:33:32,619 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:35:00,372 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:35:00,376 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:35:02,994 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:35:03,085 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:35:03,087 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:35:03,159 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:35:03,849 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:35:04,514 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:35:04,522 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:35:06,390 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
array() missing required argument 'object' (pos 0)
2023-09-03 21:35:06,402 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:35:53,695 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:35:53,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:35:56,292 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:35:56,381 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:35:56,383 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:35:56,455 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:35:57,137 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:35:57,801 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:35:57,809 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:35:59,731 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
name 'logreg' is not defined
2023-09-03 21:35:59,743 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:36:46,520 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:36:46,524 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:36:49,135 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:36:49,224 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:36:49,226 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:36:49,298 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:36:49,976 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:36:50,637 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:36:50,646 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:36:54,210 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:36:54,224 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
name 'accuracy_score' is not defined
2023-09-03 21:36:54,237 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:37:32,890 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:37:32,893 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:37:45,295 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:37:45,299 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:37:47,827 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:37:47,919 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:37:47,921 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:37:47,992 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:37:48,679 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:37:49,344 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:37:49,353 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:37:52,952 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:37:52,967 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
name 'accuracy_score' is not defined
2023-09-03 21:37:52,980 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:38:19,419 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:38:19,423 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:38:21,948 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:38:22,039 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:38:22,041 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:38:22,114 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:38:22,793 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:38:23,456 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:38:23,465 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:38:27,036 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:38:27,070 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None' failed with error: 
name 'submission_binary' is not defined
2023-09-03 21:38:27,083 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:38:45,177 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:38:45,180 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:38:47,729 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:38:47,819 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:38:47,821 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:38:47,893 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:38:48,575 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:38:49,237 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:38:49,246 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> None
2023-09-03 21:38:52,836 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:38:54,514 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:38:56,171 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:38:57,866 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:38:59,516 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:39:01,100 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:39:01,240 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 21:39:01,242 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 21:52:01,699 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:52:01,703 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:52:04,046 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:52:04,136 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:52:04,137 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:52:04,210 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:52:04,892 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:52:05,559 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:52:05,567 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
2023-09-03 21:52:09,103 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:09,134 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]' failed with error: 
name 'submission_binary' is not defined
2023-09-03 21:52:09,145 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 21:52:39,598 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:52:39,601 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:52:42,135 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:52:42,228 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:52:42,230 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:52:42,301 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:52:42,983 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:52:43,645 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:52:43,654 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
2023-09-03 21:52:47,236 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:48,906 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:50,550 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:52,232 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:53,874 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:55,449 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:52:55,520 - kedro.io.data_catalog - INFO - Saving data to 'submission_tfidf_logreg' (CSVDataSet)...
2023-09-03 21:52:56,867 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 21:52:56,869 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-03 21:59:40,464 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 21:59:40,468 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 21:59:42,992 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 21:59:43,083 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 21:59:43,085 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 21:59:43,157 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 21:59:43,843 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 21:59:44,505 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 21:59:44,514 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
2023-09-03 21:59:48,103 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 21:59:48,478 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]' failed with error: 
blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 159571, expected 153164.
2023-09-03 21:59:48,492 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 22:02:30,616 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 22:02:30,620 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 22:02:33,063 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 22:02:33,153 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 22:02:33,154 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 22:02:33,227 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 22:02:33,954 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 22:02:34,653 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 22:02:34,661 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
2023-09-03 22:02:38,554 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:02:38,628 - kedro.pipeline.node - ERROR - Node 'z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]' failed with error: 
too many indices for array: array is 1-dimensional, but 2 were indexed
2023-09-03 22:02:38,642 - kedro.runner.sequential_runner - WARNING - No nodes ran. Repeat the previous command to attempt a new run.
2023-09-03 22:03:15,041 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-03 22:03:15,045 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-03 22:03:17,602 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-03 22:03:17,692 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-03 22:03:17,693 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-03 22:03:17,766 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-03 22:03:18,451 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-03 22:03:19,116 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-03 22:03:19,125 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
2023-09-03 22:03:22,699 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:03:24,663 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:03:26,529 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:03:28,280 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:03:30,054 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:03:31,806 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-09-03 22:03:31,989 - kedro.io.data_catalog - INFO - Saving data to 'submission_tfidf_logreg' (CSVDataSet)...
2023-09-03 22:03:33,351 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-03 22:03:33,353 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-04 13:44:31,441 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:44:31,444 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:45:16,500 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:45:16,503 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:45:34,051 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:45:34,055 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:45:43,295 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:45:43,298 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:45:58,480 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:45:58,484 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:47:33,267 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:47:33,270 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:47:37,385 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py:359: UserWarning: An error occurred while importing the 'granlp.pipelines.build_graph' module. Nothing defined therein will be returned by 'find_pipelines'.

Traceback (most recent call last):
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py", line 357, in find_pipelines
    pipeline_module = importlib.import_module(pipeline_module_name)
  File "/home/mohamed-amine.rguig/tools/python/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/__init__.py", line 6, in <module>
    from .pipeline import create_pipeline
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/pipeline.py", line 7, in <module>
    from .nodes import build_graph
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py", line 23, in <module>
    from .utils.Bert_processing import MultiLabelDataset
ModuleNotFoundError: No module named 'granlp.pipelines.build_graph.utils'

  warnings.warn(

2023-09-04 13:47:37,504 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-04 13:47:38,177 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-04 13:47:38,838 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-04 13:47:38,846 - kedro.pipeline.node - INFO - Running node: zeb: loading([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-04 13:47:56,234 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:47:56,237 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:48:00,023 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py:359: UserWarning: An error occurred while importing the 'granlp.pipelines.build_graph' module. Nothing defined therein will be returned by 'find_pipelines'.

Traceback (most recent call last):
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py", line 357, in find_pipelines
    pipeline_module = importlib.import_module(pipeline_module_name)
  File "/home/mohamed-amine.rguig/tools/python/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/__init__.py", line 6, in <module>
    from .pipeline import create_pipeline
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/pipeline.py", line 7, in <module>
    from .nodes import build_graph
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py", line 23, in <module>
    from .utils.Bert_processing import MultiLabelDataset
ModuleNotFoundError: No module named 'granlp.pipelines.build_graph.utils'

  warnings.warn(

2023-09-04 13:48:00,143 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-04 13:48:00,828 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-04 13:48:01,497 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-04 13:48:01,505 - kedro.pipeline.node - INFO - Running node: zeb: loading([train_comments_processed,test_comments_processed,params:parameters]) -> [train_dt,val_dt,test_dt]
2023-09-04 13:48:21,352 - kedro.io.data_catalog - INFO - Saving data to 'train_dt' (PickleDataSet)...
2023-09-04 13:48:22,399 - kedro.io.data_catalog - INFO - Saving data to 'val_dt' (PickleDataSet)...
2023-09-04 13:48:23,088 - kedro.io.data_catalog - INFO - Saving data to 'test_dt' (PickleDataSet)...
2023-09-04 13:48:24,146 - kedro.runner.sequential_runner - INFO - Completed 1 out of 1 tasks
2023-09-04 13:48:24,147 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2023-09-04 13:56:45,404 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 13:56:45,407 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 13:56:49,247 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py:359: UserWarning: An error occurred while importing the 'granlp.pipelines.build_graph' module. Nothing defined therein will be returned by 'find_pipelines'.

Traceback (most recent call last):
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py", line 357, in find_pipelines
    pipeline_module = importlib.import_module(pipeline_module_name)
  File "/home/mohamed-amine.rguig/tools/python/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/__init__.py", line 6, in <module>
    from .pipeline import create_pipeline
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/pipeline.py", line 7, in <module>
    from .nodes import build_graph
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py", line 23, in <module>
    from .utils.Bert_processing import MultiLabelDataset
ModuleNotFoundError: No module named 'granlp.pipelines.build_graph.utils'

  warnings.warn(

2023-09-04 13:56:49,365 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-04 13:56:50,801 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-04 13:56:50,803 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-04 13:56:52,150 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-04 13:56:52,813 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-04 13:56:53,487 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-04 13:56:55,083 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
2023-09-04 14:02:31,605 - kedro.framework.session.session - INFO - Kedro project granlp
2023-09-04 14:02:31,608 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/session/session.py:266: FutureWarning: ConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader
  warnings.warn(

2023-09-04 14:02:35,441 - py.warnings - WARNING - /vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py:359: UserWarning: An error occurred while importing the 'granlp.pipelines.build_graph' module. Nothing defined therein will be returned by 'find_pipelines'.

Traceback (most recent call last):
  File "/vol/home/mohamed-amine.rguig/env/lib/python3.10/site-packages/kedro/framework/project/__init__.py", line 357, in find_pipelines
    pipeline_module = importlib.import_module(pipeline_module_name)
  File "/home/mohamed-amine.rguig/tools/python/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/__init__.py", line 6, in <module>
    from .pipeline import create_pipeline
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/pipeline.py", line 7, in <module>
    from .nodes import build_graph
  File "/vol/home/mohamed-amine.rguig/granlp/src/granlp/pipelines/build_graph/nodes.py", line 23, in <module>
    from .utils.Bert_processing import MultiLabelDataset
ModuleNotFoundError: No module named 'granlp.pipelines.build_graph.utils'

  warnings.warn(

2023-09-04 14:02:35,559 - kedro.io.data_catalog - INFO - Loading data from 'train_dt' (PickleDataSet)...
2023-09-04 14:02:37,002 - kedro.io.data_catalog - INFO - Loading data from 'val_dt' (PickleDataSet)...
2023-09-04 14:02:37,004 - kedro.io.data_catalog - INFO - Loading data from 'test_dt' (PickleDataSet)...
2023-09-04 14:02:38,355 - kedro.io.data_catalog - INFO - Loading data from 'train_comments_processed' (CSVDataSet)...
2023-09-04 14:02:39,018 - kedro.io.data_catalog - INFO - Loading data from 'test_comments_processed' (CSVDataSet)...
2023-09-04 14:02:39,676 - kedro.io.data_catalog - INFO - Loading data from 'params:parameters' (MemoryDataset)...
2023-09-04 14:02:41,251 - kedro.pipeline.node - INFO - Running node: z: train([train_dt,val_dt,test_dt,train_comments_processed,test_comments_processed,params:parameters]) -> [submission_tfidf_logreg]
